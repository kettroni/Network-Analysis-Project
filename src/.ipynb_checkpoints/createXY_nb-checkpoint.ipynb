{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Distance for edge (x,y)\n",
    "def JD(G,x,y):\n",
    "    neighs_x = set(G.neighbors(x))\n",
    "    neighs_y = set(G.neighbors(y))\n",
    "    if len(neighs_x) == 0 or len(neighs_y) == 0:\n",
    "        return 0\n",
    "    a = len(neighs_x.intersection(neighs_y))\n",
    "    b = len(neighs_x.union(neighs_y))\n",
    "    return a/b\n",
    "\n",
    "# Create a page rank file from graph with pickle\n",
    "def PR_file(G, path, a = 0.85):\n",
    "    pr = nx.pagerank(G, alpha=a)\n",
    "    pickle.dump(pr,open(path, 'wb'))\n",
    "    \n",
    "# Return Adamic/Adar Index for edge (x,y)\n",
    "def AdamicAdarIndex(G,x,y):\n",
    "    neighs_x = set(G.neighbors(x))\n",
    "    neighs_y = set(G.neighbors(y))\n",
    "    inter = neighs_x.intersection(neighs_y)\n",
    "    sum = 0\n",
    "    if len(inter) > 0:\n",
    "        for com in inter:\n",
    "            deg = G.degree[com]\n",
    "            sum = sum + (1/math.log(deg))\n",
    "    return sum\n",
    "\n",
    "# Create a HITS file from graph with pickle\n",
    "def HITS(G, path):\n",
    "    hits = nx.hits(G, max_iter=500, tol=1e-08, nstart=None, normalized=True)\n",
    "    pickle.dump(hits,open(path, 'wb'))\n",
    "\n",
    "# Create a category file from '/data/categories' to dictionary with pickle, takes tsv as input\n",
    "def categories(in_file, out_file):\n",
    "    with open(in_file) as fp:\n",
    "        line = fp.readline()\n",
    "        categories = []\n",
    "        cat_dict = dict()\n",
    "        while line:\n",
    "            \n",
    "            splitted = re.split(r'\\t+', line)\n",
    "            \n",
    "            # article\n",
    "            x = splitted[0]\n",
    "            cat_dict[x] = set()\n",
    "            \n",
    "            # categories of article x\n",
    "            cat = splitted[1]\n",
    "            \n",
    "            # Take main category\n",
    "            x_cats = cat.split('.')\n",
    "            \n",
    "            for cat_i in x_cats:\n",
    "                x_cat = cat_i.split('\\n')[0]\n",
    "                \n",
    "                if x_cat in categories:\n",
    "                    temp = cat_dict[x]\n",
    "                    temp.add(categories.index(x_cat))\n",
    "                    cat_dict[x] = temp\n",
    "                else:\n",
    "                    temp = cat_dict[x]\n",
    "                    temp.add(len(categories))\n",
    "                    cat_dict[x] = temp\n",
    "                    categories.append(x_cat)\n",
    "            line = fp.readline()\n",
    "        pickle.dump(cat_dict,open(out_file, 'wb'))\n",
    "        pickle.dump(categories,open('../data/numberToCategoryNameList.pkl', 'wb'))\n",
    "\n",
    "#categories('../data/categoriesDecoded.tsv', '../data/getCategoryFromLinkDict.pkl')\n",
    "\n",
    "# Create X vector (tuple) for edge (x,y) in graph G\n",
    "def create_X(G,x,y, categories_dict, pr, hits):\n",
    "    jd = JD(G,x,y)\n",
    "    aa = AdamicAdarIndex(G,x,y)\n",
    "    \n",
    "    cats_x = set()\n",
    "    cats_y = set()\n",
    "    try:\n",
    "        cats_x = categories_dict[x]\n",
    "        cats_y = categories_dict[y]\n",
    "    except:\n",
    "        pass\n",
    "    no_comm = len(cats_x.intersection(cats_y))\n",
    "    \n",
    "    pr_x = pr[x]\n",
    "    pr_y = pr[y]\n",
    "    \n",
    "    hits_x = hits[0][x]\n",
    "    hits_y = hits[0][y]\n",
    "    \n",
    "    return no_comm, jd, aa, pr_x, pr_y, hits_x, hits_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original network\n",
    "G = nx.read_edgelist('../data/decoded.tsv', delimiter = '\\t', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HITS and PR\n",
    "HITS(G, '../data/hitsOrig.pkl')\n",
    "PR_file(G, '../data/PROrig.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = []\n",
    "with open('../data/hitsOrig.pkl', 'rb') as f:\n",
    "    hits = pickle.load(f)\n",
    "    \n",
    "pr = []\n",
    "with open('../data/PROrig.pkl', 'rb') as f:\n",
    "    pr = pickle.load(f)\n",
    "    \n",
    "cat_dict = []\n",
    "with open('../data/getCategoryFromLinkDict.pkl', 'rb') as f:\n",
    "    cat_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over edges and create XY data for them\n",
    "vecs = []\n",
    "ys = []\n",
    "for e in G.edges:\n",
    "    x = e[0]\n",
    "    y = e[1]\n",
    "    \n",
    "    vec = create_X(G,x,y, cat_dict, pr, hits)\n",
    "    vecs.append(vec)\n",
    "    ys.append(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over edges that don't exist\n",
    "for u in G.nodes():\n",
    "    i = 0\n",
    "    for v in G.nodes(): \n",
    "        if i > 30:\n",
    "            break  \n",
    "        if u == v:\n",
    "            continue\n",
    "        if G.has_edge(u,v):\n",
    "            continue\n",
    "        vecs.append(create_X(G,u,v, cat_dict, pr, hits))\n",
    "        ys.append(0)\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump X and y with pickle\n",
    "\n",
    "# Transform vecs from tuples to list\n",
    "X_data = [list(item) for item in vecs]\n",
    "pickle.dump(X_data,open('../data/X_data.pkl', 'wb'))\n",
    "pickle.dump(ys,open('../data/Y_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = nx.read_edgelist(\"data/decoded.tsv\")\n",
    "\n",
    "#print(nx.info(g))\n",
    "pd.read_csv('data/decoded.tsv',nrows=80, delimiter='\\t').to_csv('data/decodedSample.tsv', sep='\\t',header=False,index=False)\n",
    "\n",
    "#reading the edgelist in a variable using networkX\n",
    "subgraph=nx.read_edgelist('data/decodedSample.tsv',delimiter='\\t',create_using=nx.DiGraph())\n",
    "#plotting the graph\n",
    "print(nx.info(subgraph))\n",
    "pos=nx.spring_layout(subgraph)\n",
    "nx.draw(subgraph,pos,node_color='#A0CBE2',edge_color='#00bb5e',width=1,edge_cmap=plt.cm.Blues,with_labels=True)\n",
    "plt.savefig(\"graph_sample.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
